{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8093ac",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  text-align: center; \n",
    "  padding: 1em; \n",
    "  margin: 0 auto 1em auto; \n",
    "  max-width: 90%; \n",
    "  border: 2px solid #00B050; \n",
    "  border-radius: 10px; \n",
    "  background-color: #f9fff9; \n",
    "  box-sizing: border-box;\n",
    "\">\n",
    "  <h1 style=\"margin-bottom: 0.2em; color: #006400;\">From Taylor Expansions to Gradient Descent</h1>\n",
    "  <h3 style=\"margin-top: 0; color: #006400; font-style: italic;\">\n",
    "    Aligned with Lecture 2A-II: Gradient Descent (and Beyond)\n",
    "  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18268125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import infra.plot as plot\n",
    "import lib.gradient_descent as GD\n",
    "# dev-only\n",
    "# import importlib\n",
    "# importlib.reload(plot)\n",
    "# importlib.reload(GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b356968",
   "metadata": {},
   "source": [
    "## 2.1: Visualizing local approximations w/ Taylor Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04b322",
   "metadata": {},
   "source": [
    "Recall from lecture of our goal: \"minimize a function $l$ efficiently\"\n",
    "- What is available:\n",
    "  - **You can evaluate the function** - for any $W$, you can compute $l(W)$\n",
    "  - **Function is differentiable** - you can compute the gradient (first derivative) at any given point $W$\n",
    "  - **Local information is accessible** - you know what's happening in the neighborhood of your current point\n",
    "- What is unknown:\n",
    "  - **No global structure** - you don't know where is the global minimum\n",
    "  - **No closed-form minimum** - you cannot analytically solve for $argmin_W\\ l(W)$\n",
    "  - **No guarantee of convexity** - there may exist local minima\n",
    "- Notation in ML context:\n",
    "  - $l$: loss function that measures model error\n",
    "  - $W$: the set of learnable parameters adjusted via optimization methods to reduce model error\n",
    "\n",
    "To build intuition for gradient-based optimization, we visualize how a function behaves near a point by using its Taylor approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31ec0b",
   "metadata": {},
   "source": [
    "### $1^{st}$ Taylor Approximation on an \"ugly\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd14bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_str = \"sin(3*W) * exp(-W**2) + 0.3 * W\"\n",
    "plot.ml2_show_taylor_order_k(func_str, k=1, w0=0.7, w_range=(0, 1.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96a52c",
   "metadata": {},
   "source": [
    "### When first-order isn't enough: a case for $2^{nd}$ insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_str = \"W**4 - 3*W**2\"\n",
    "plot.ml2_show_taylor_order_k(func_str, k=1, w0=0, w_range=(-1.5, 1.5))\n",
    "plot.ml2_show_taylor_order_k(func_str, k=2, w0=0, w_range=(-1.5, 1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a5f11",
   "metadata": {},
   "source": [
    "### [Lab Exercise] Test your own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define your own function in `func_str` as a python string\n",
    "#   Available math function: \n",
    "#       sin, cos, tan, cot, sec, csc, asin, acos, atan, \n",
    "#       sinh, cosh, tanh, exp, log, ln, sqrt, abs\n",
    "#   Available constants:\n",
    "#       pi, E (Eulerâ€™s number), oo (Inf)\n",
    "#   Available operators:\n",
    "#       +, -, *, /, **, ()\n",
    "func_str = \"sin(W)\"\n",
    "\n",
    "# TODO: modify the function parameters below\n",
    "#   `k`: order of taylor expansion\n",
    "#   `w0`: the expansion is around W=w0\n",
    "#   `w_range`: a tuple representing start/end value on x-axis\n",
    "plot.ml2_show_taylor_order_k(\n",
    "    func_str, \n",
    "    k = 1, \n",
    "    w0 = 0, \n",
    "    w_range = (-1.5, 6.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270552f2",
   "metadata": {},
   "source": [
    "## 2.2: Full-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d700e2",
   "metadata": {},
   "source": [
    "Conceptual clarification\n",
    "- **Binary Classification**: a task whose goal is to classify inputs into one out of two classes.\n",
    "- **Linear Classification**: a method (e.g., perceptron) that uses a linear decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c83f1",
   "metadata": {},
   "source": [
    "### Base version of GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"case\": 2, \"lr\": 0.1, \"tr_mode\": \"gd\",}\n",
    "\n",
    "exp = GD.LinearGDExp(case_study=cfg['case'], lr=cfg['lr'], mode=cfg['tr_mode'])\n",
    "exp.exec(verbose=True)\n",
    "plot.ml2_show_dataset_2d(case=cfg['case'])\n",
    "plot.ml2_show_stats(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de00a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.ml2_gen_w_seq(cfg, lastepoch=-1)\n",
    "plot.ml2_animate(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a09f8",
   "metadata": {},
   "source": [
    "### [Lab Exercise] Find a better LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe500e0",
   "metadata": {},
   "source": [
    "Now we switch to a more challanging dataset (w/ larger noise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"case\": 3, \"lr\": 0.1, \"tr_mode\": \"gd\",}\n",
    "\n",
    "exp = GD.LinearGDExp(case_study=cfg['case'], lr=cfg['lr'], mode=cfg['tr_mode'])\n",
    "exp.exec(verbose=True)\n",
    "plot.ml2_show_dataset_2d(case=cfg['case'])\n",
    "plot.ml2_show_stats(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd598684",
   "metadata": {},
   "source": [
    "Under fixed number of epoch, try to change the LR parameter and observe the effect (e.g., 0.005, 1, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cae54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify the param `lr` below\n",
    "cfg = {\"case\": 3, \"lr\": 0.1, \"tr_mode\": \"gd\",}\n",
    "\n",
    "exp = GD.LinearGDExp(case_study=cfg['case'], lr=cfg['lr'], mode=cfg['tr_mode'])\n",
    "exp.exec(verbose=True)\n",
    "plot.ml2_show_stats(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c0540",
   "metadata": {},
   "source": [
    "## 2.3: Compare SGD with GD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c7216",
   "metadata": {},
   "source": [
    "A faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493cb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"case\": 3, \"lr\": 0.05, \"tr_mode\": \"sgd\",}\n",
    "\n",
    "exp = GD.LinearGDExp(case_study=cfg['case'], lr=cfg['lr'], mode=cfg['tr_mode'])\n",
    "exp.exec(verbose=False)\n",
    "plot.ml2_show_stats(cfg)\n",
    "plot.ml2_gen_w_seq(cfg, lastepoch=-1)\n",
    "plot.ml2_animate(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828b6a0",
   "metadata": {},
   "source": [
    "Visualize the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ea8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg1 = {\"case\": 1, \"lr\": 0.5, \"tr_mode\": \"gd\",}\n",
    "exp = GD.LinearGDExp(case_study=cfg1['case'], lr=cfg1['lr'], mode=cfg1['tr_mode'])\n",
    "# exp.exec(verbose=False)\n",
    "cfg2 = {\"case\": 1, \"lr\": 0.5, \"tr_mode\": \"sgd\",}\n",
    "exp = GD.LinearGDExp(case_study=cfg2['case'], lr=cfg2['lr'], mode=cfg2['tr_mode'])\n",
    "# exp.exec(verbose=False)\n",
    "plot.show_trajectory(cfg1, cfg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.ml2_show_stats(cfg1)\n",
    "plot.ml2_show_stats(cfg2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
